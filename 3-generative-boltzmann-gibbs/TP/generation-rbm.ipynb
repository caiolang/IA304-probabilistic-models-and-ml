{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from rbm import RBM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = scipy.io.loadmat('binaryalphadigs.mat')\n",
    "data = np.array(mat['dat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lire_alpha_digits\n",
    "def read_alpha_digits(data, digits):\n",
    "    \"\"\"Read digits from the AlphaDigits dataset\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : np.array\n",
    "    digits : List[int]\n",
    "        Indexes of the digit classes to read\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.array\n",
    "        Array of all the samples from requested digits, in binary array form \n",
    "    \"\"\"    \n",
    "    read_data = np.take(data.copy(), digits, axis=0)\n",
    "    read_data = np.reshape(read_data, (len(digits) * read_data.shape[1]))\n",
    "    return np.array(list(read_data))\n",
    "\n",
    "# read_alpha_digits(data, [10, 11, 12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_samples(X, n_rows = 10, n_cols = 10, fig_x=10, fig_y=10):\n",
    "    \"\"\"\n",
    "    Display a grid of samples.\n",
    "    Samples are chosen randomly if there are more samples than n_rows X n_cols.\n",
    "    \"\"\"\n",
    "\n",
    "    # Configs\n",
    "    plt.figure(figsize=(fig_x,fig_y)) ## Create figure\n",
    "    n = X.shape[0] # Obtain number of samples to display\n",
    "\n",
    "    if n <= n_rows * n_cols: \n",
    "        # If number of samples fits in the columns/rows\n",
    "        samples_idx = np.arange(n)\n",
    "        if n < n_rows * n_cols:\n",
    "            n_rows = n // n_cols + 1\n",
    "    else: \n",
    "        # If not, choose randomly which images to show\n",
    "        samples_idx = np.random.choice(n, size=n_rows * n_cols, replace=False)\n",
    "\n",
    "    for k, idx in enumerate(samples_idx):\n",
    "        plt.subplot(n_rows, n_cols, k+1)\n",
    "        plt.imshow(X[idx], cmap=plt.get_cmap('gray'))\n",
    "\n",
    "        # Hide ticks\n",
    "        # plt.axis('off')\n",
    "        plt.xticks([], [])\n",
    "        plt.yticks([], [])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "digits = read_alpha_digits(data, [10, 11, 12])\n",
    "# display_samples(digits)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_digit_idx = [10,11,12]\n",
    "digits = read_alpha_digits(data, input_digit_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_samples(digits)\n",
    "print(digits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits_vecs = digits.reshape(len(input_digit_idx)*39,20*16)\n",
    "\n",
    "print(digits_vecs.shape)\n",
    "print(digits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------\n",
    "# Constants\n",
    "# ---------\n",
    "# Data dample dim\n",
    "p = 20*16 # For Binary AlphaDigits\n",
    "# Latent vector dim\n",
    "q = 100\n",
    "\n",
    "rbm = RBM(p,q)\n",
    "rbm.train_RBM(digits_vecs, batch_size=4, n_epoch=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rbm.generate_data(100, nb_iter_gibbs=100, random_init=True)\n",
    "display_samples(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = rbm.generate_data(100, nb_iter_gibbs=100, random_init=False)\n",
    "display_samples(out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse de l'erreur de reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = read_alpha_digits(data, [10])\n",
    "digits_vecs = digits.reshape(39,20*16)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionality of hidden layer (q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 20 * 16\n",
    "errors = []\n",
    "for q in range(20, 400, 20):\n",
    "    rbm = RBM(p, q)\n",
    "    rbm.train_RBM(digits_vecs, batch_size=4, n_epoch=100, verbose=False)\n",
    "    \n",
    "    errors.append(np.mean(np.power(digits_vecs - rbm.decode(rbm.encode(digits_vecs)),2)))\n",
    "\n",
    "sns.lineplot(x=range(20, 400, 20), y=errors)\n",
    "# y: reconstruction error\n",
    "# x: number of hidden units"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 100\n",
    "errors_batch_size = []\n",
    "for batch_size in range(1, 40, 1):\n",
    "    rbm = RBM(p, q)\n",
    "    rbm.train_RBM(digits_vecs, batch_size=batch_size, n_epoch=100, verbose=False)\n",
    "    \n",
    "    errors_batch_size.append(np.mean(np.power(digits_vecs - rbm.decode(rbm.encode(digits_vecs)),2)))\n",
    "\n",
    "sns.lineplot(x=range(1, 40, 1), y=errors_batch_size)\n",
    "# y: reconstruction error\n",
    "# x: batch size\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse en fonction du nombre de caractères à apprendre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = []\n",
    "p = 20*16\n",
    "q = 100\n",
    "errors = []\n",
    "outs = []\n",
    "for new_digit in range(10, len(data)):\n",
    "    digits.append(new_digit)\n",
    "    digits_vecs = read_alpha_digits(data, digits).reshape((-1, 20*16))\n",
    "\n",
    "    rbm = RBM(p, q)\n",
    "    rbm.train_RBM(digits_vecs, batch_size=4, n_epoch=100, verbose=False)\n",
    "    errors.append(np.mean(np.power(digits_vecs - rbm.decode(rbm.encode(digits_vecs)),2)))\n",
    "    #rbm.generate_data(4, nb_iter_gibbs=5)\n",
    "\n",
    "sns.lineplot(x=range(1, len(data) - 9), y=errors)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse avec MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "mnist = datasets.fetch_openml('mnist_784')\n",
    "# Make mnist binary\n",
    "# digits = (digits > 8) * 1\n",
    "# display_samples(digits.reshape((-1, 8, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_digits = mnist.data.to_numpy()\n",
    "display_samples(mnist_digits.reshape((-1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make digits binary\n",
    "mnist_digits_bin = (mnist_digits > 128) * 1\n",
    "display_samples(mnist_digits_bin.reshape((-1, 28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test = train_test_split(mnist_digits_bin, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a RBM in MNIST\n",
    "p = 28*28\n",
    "q = 400\n",
    "rbm = RBM(p, q)\n",
    "rbm.train_RBM(X_train, batch_size=256, n_epoch=100, verbose=True)\n",
    "rbm.generate_data(10, nb_iter_gibbs=100, height=28, width=28)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "datascience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a22db4230d00807ed5427721d49a8f3ad06b4b9a9e65d29f137559ca1433c876"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
